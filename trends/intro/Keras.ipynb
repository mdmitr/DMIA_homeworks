{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, cv2, re, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from keras import layers, models, optimizers\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = 150\n",
    "img_height = 150\n",
    "TRAIN_DIR = 'train/'\n",
    "TEST_DIR = 'test/'\n",
    "train_images_dogs_cats = [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR)] # use this for full dataset\n",
    "test_images_dogs_cats = [TEST_DIR+i for i in os.listdir(TEST_DIR)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    return [ atoi(c) for c in re.split('(\\d+)', text) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Sort the traning set. Use 1300 images each of cats and dogs instead of all 25000 to speed up the learning process.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_dogs_cats.sort(key=natural_keys)\n",
    "train_images_dogs_cats = train_images_dogs_cats[0:1300] + train_images_dogs_cats[12500:13800] \n",
    "\n",
    "test_images_dogs_cats.sort(key=natural_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(list_of_images):\n",
    "    \"\"\"\n",
    "    Returns two arrays: \n",
    "        x is an array of resized images\n",
    "        y is an array of labels\n",
    "    \"\"\"\n",
    "    x = [] # images as arrays\n",
    "    y = [] # labels\n",
    "    \n",
    "    for image in list_of_images:\n",
    "        x.append(cv2.resize(cv2.imread(image), (img_width,img_height), interpolation=cv2.INTER_CUBIC))\n",
    "    \n",
    "    for i in list_of_images:\n",
    "        if 'dog' in i:\n",
    "            y.append(1)\n",
    "        elif 'cat' in i:\n",
    "            y.append(0)\n",
    "        #else:\n",
    "            #print('neither cat nor dog name present in images')\n",
    "            \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channels_last\n"
     ]
    }
   ],
   "source": [
    "X, Y = prepare_data(train_images_dogs_cats)\n",
    "print(K.image_data_format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First split the data in two sets, 80% for training, 20% for Val/Test)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X,Y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train_samples = len(X_train)\n",
    "nb_validation_samples = len(X_val)\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mdmitrievsky\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1255: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Users\\mdmitrievsky\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1340: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 148, 148, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 72, 72, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 72, 72, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 36, 36, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 34, 34, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 34, 34, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 17, 17, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18496)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                1183808   \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,212,513\n",
      "Trainable params: 1,212,513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), input_shape=(img_width, img_height, 3)))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3)))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3)))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1))\n",
    "model.add(layers.Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow(np.array(X_train), Y_train, batch_size=batch_size)\n",
    "validation_generator = val_datagen.flow(np.array(X_val), Y_val, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "130/130 [==============================] - 12s 90ms/step - loss: 0.7084 - acc: 0.5399 - val_loss: 0.6604 - val_acc: 0.5957\n",
      "Epoch 2/30\n",
      "130/130 [==============================] - 9s 72ms/step - loss: 0.6611 - acc: 0.6168 - val_loss: 0.6133 - val_acc: 0.6699\n",
      "Epoch 3/30\n",
      "130/130 [==============================] - 9s 73ms/step - loss: 0.6283 - acc: 0.6524 - val_loss: 0.6074 - val_acc: 0.6855\n",
      "Epoch 4/30\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.6036 - acc: 0.6937 - val_loss: 0.5610 - val_acc: 0.7090\n",
      "Epoch 5/30\n",
      "130/130 [==============================] - 10s 77ms/step - loss: 0.5828 - acc: 0.7034 - val_loss: 0.5353 - val_acc: 0.7363\n",
      "Epoch 6/30\n",
      "130/130 [==============================] - 10s 78ms/step - loss: 0.5669 - acc: 0.7255 - val_loss: 0.5496 - val_acc: 0.7129\n",
      "Epoch 7/30\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.5522 - acc: 0.7413 - val_loss: 0.5587 - val_acc: 0.7012\n",
      "Epoch 8/30\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.5371 - acc: 0.7433 - val_loss: 0.6027 - val_acc: 0.6973\n",
      "Epoch 9/30\n",
      "130/130 [==============================] - 9s 72ms/step - loss: 0.5310 - acc: 0.7447 - val_loss: 0.5823 - val_acc: 0.7324\n",
      "Epoch 10/30\n",
      "130/130 [==============================] - 9s 71ms/step - loss: 0.5219 - acc: 0.7466 - val_loss: 0.5716 - val_acc: 0.7188\n",
      "Epoch 11/30\n",
      "130/130 [==============================] - 9s 72ms/step - loss: 0.5021 - acc: 0.7750 - val_loss: 0.6237 - val_acc: 0.7422\n",
      "Epoch 12/30\n",
      "130/130 [==============================] - 9s 72ms/step - loss: 0.4788 - acc: 0.7731 - val_loss: 0.5418 - val_acc: 0.7734\n",
      "Epoch 13/30\n",
      "130/130 [==============================] - 9s 73ms/step - loss: 0.4833 - acc: 0.7779 - val_loss: 0.5337 - val_acc: 0.7422\n",
      "Epoch 14/30\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.4714 - acc: 0.7913 - val_loss: 0.5639 - val_acc: 0.7695\n",
      "Epoch 15/30\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.4610 - acc: 0.7899 - val_loss: 0.5488 - val_acc: 0.7773\n",
      "Epoch 16/30\n",
      "130/130 [==============================] - 10s 74ms/step - loss: 0.4721 - acc: 0.7856 - val_loss: 0.5535 - val_acc: 0.7676\n",
      "Epoch 17/30\n",
      "130/130 [==============================] - 9s 73ms/step - loss: 0.4719 - acc: 0.7942 - val_loss: 0.4941 - val_acc: 0.7676\n",
      "Epoch 18/30\n",
      "130/130 [==============================] - 10s 73ms/step - loss: 0.4449 - acc: 0.8067 - val_loss: 0.6682 - val_acc: 0.7383\n",
      "Epoch 19/30\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.4464 - acc: 0.8038 - val_loss: 0.5962 - val_acc: 0.7480\n",
      "Epoch 20/30\n",
      "130/130 [==============================] - 9s 72ms/step - loss: 0.4767 - acc: 0.7981 - val_loss: 0.5661 - val_acc: 0.7422\n",
      "Epoch 21/30\n",
      "130/130 [==============================] - 9s 73ms/step - loss: 0.4338 - acc: 0.8053 - val_loss: 0.4675 - val_acc: 0.7969\n",
      "Epoch 22/30\n",
      "130/130 [==============================] - 9s 71ms/step - loss: 0.4406 - acc: 0.8043 - val_loss: 0.5062 - val_acc: 0.7617\n",
      "Epoch 23/30\n",
      "130/130 [==============================] - 9s 71ms/step - loss: 0.4338 - acc: 0.8034 - val_loss: 0.5458 - val_acc: 0.7578\n",
      "Epoch 24/30\n",
      "130/130 [==============================] - 9s 72ms/step - loss: 0.4343 - acc: 0.8067 - val_loss: 0.5763 - val_acc: 0.7656\n",
      "Epoch 25/30\n",
      "130/130 [==============================] - 9s 73ms/step - loss: 0.4267 - acc: 0.8240 - val_loss: 0.4638 - val_acc: 0.7773\n",
      "Epoch 26/30\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.4523 - acc: 0.8135 - val_loss: 0.5156 - val_acc: 0.7734\n",
      "Epoch 27/30\n",
      "130/130 [==============================] - 9s 73ms/step - loss: 0.4073 - acc: 0.8202 - val_loss: 0.5744 - val_acc: 0.7461\n",
      "Epoch 28/30\n",
      "130/130 [==============================] - 9s 71ms/step - loss: 0.4458 - acc: 0.8120 - val_loss: 0.6214 - val_acc: 0.7598\n",
      "Epoch 29/30\n",
      "130/130 [==============================] - 9s 72ms/step - loss: 0.4289 - acc: 0.8159 - val_loss: 0.5077 - val_acc: 0.7891\n",
      "Epoch 30/30\n",
      "130/130 [==============================] - 10s 74ms/step - loss: 0.4272 - acc: 0.8159 - val_loss: 0.5122 - val_acc: 0.7793\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    history = model.fit_generator(\n",
    "        train_generator, \n",
    "        steps_per_epoch=nb_train_samples // batch_size,\n",
    "        epochs=30,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=nb_validation_samples // batch_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('model_wieghts.h5')\n",
    "model.save('model_keras.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, Y_test = prepare_data(test_images_dogs_cats) #Y_test in this case will be []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1. / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 9s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagen.flow(np.array(X_test), batch_size=batch_size)\n",
    "prediction_probabilities = model.predict_generator(test_generator, verbose=1, steps=782)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12500, 1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_probabilities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.image.NumpyArrayIterator at 0x3ac2566630>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12500"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "counter = range(1, len(test_images_dogs_cats) + 1)\n",
    "solution = pd.DataFrame({\"id\": counter, \"label\":list(prediction_probabilities)})\n",
    "cols = ['label']\n",
    "\n",
    "for col in cols:\n",
    "    solution[col] = solution[col].map(lambda x: str(x).lstrip('[').rstrip(']')).astype(float)\n",
    "\n",
    "solution.to_csv(\"dogsVScats.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
